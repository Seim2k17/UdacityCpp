
4.1 Heap

- flexible and "dangerous" ressource
- dynamic memory right above the BSS / Data Segment
- it grows upwards while stack grows downwards (acc to memory adresses)
- stack automatically grows and shrinks with each function call and local variable. as soon the scope is left it deallocates mem automatically
--> not so with the heap
- programmer allocae memory with "malloc" or "new" and it will remain until deallocation (free / delete)
- many problems acc. to memory fragmentation


3.4. Call-by-value vs. call-by-reference

When calling a function as in the previous code example, its parameters (in this case myInt) are used to create local copies of the information provided by the caller. The caller is not sharing the parameter with the function but instead a proprietary copy is created using the assignment operator = (more about that later). When passing parameters in such a way, it is ensured that changes made to the local copy will not affect the original on the caller side. The upside to this is that inner workings of the function and the data owned by the caller are kept neatly separate.

However, there are two major downsides to this:

Passing parameters by value means that a copy is created, which is an expensive operation that might consume large amounts of memory, depending on the data that is being transferred. Later in this course we will encounter "move semantics", which is an effective way to compensate for this downside.
Passing by value also means that the created copy can not be used as a back channel for communicating with the caller, for example by directly writing the desired information into the variable.
Consider the example on the right in the pass_by_value.cpp file. In main, the integer val is initialized with 0. When passing it to the function AddTwo, a local copy of val is created, which only exists within the scope of AddTwo, so the add-operation has no effect on val on the caller side. So when main returns, val has a value of 2 instead of 4.


However, with a slight modification, we can easily create a backchannel to the caller side. Consider the code on the right.

In this case, when passing the parameter to the function AddThree, we are creating a local copy as well but note that we are now passing a pointer variable. This means that a copy of the memory address of val is created, which we can then use to directly modify its content by using the dereference operator *.


void AddThree(int *val)
{
    *val += 3;
}

int main()
{
    int val = 0;
    AddThree(&val);
    val += 2;

    std::cout << "val = " << val << std::endl;
 
    return 0;
}

Passing Variables by Reference
The second major way of passing parameters to a function is by reference. With this way, the function receives a reference to the parameter, rather than a copy of its value. As with the example of AddThree above, the function can now modify the argument such that the changes also happen on the caller side. In addition to the possibility to directly exchange information between function and caller, passing variables by reference is also faster as no information needs to be copied, as well as more memory-efficient.

A major disadvantage is that the caller does not always know what will happen to the data it passes to a function (especially when the function code can not be modified easily). Thus, in some cases, special steps must be taken to protect ones data from inappropriate modification.

Let us now look at an example of passing a variable by reference, shown below.

#include <iostream>

void AddFour(int &val)
{
    val += 4;
}

int main()
{
    int val = 0;
    AddFour(val);
    val += 2;

    std::cout << "val = " << val << std::endl;
 
    return 0;
}

To pass a variable by reference, we simply declare the function parameters as references using & rather than as normal variables. When the function is called, val will become a reference to the argument. Since a reference to a variable is treated exactly the same as the variable itself, any changes made to the reference are passed through to the argument!

Pointers vs. References
As we have seen in the examples above, the use of pointers and references to directly manipulate function arguments in a memory-effective way is very similar. Let us compare the two methods in the code on the right.


void AddFour(int &val)
{
    val += 4;
}

void AddSix(int *val)
{
    *val += 6; 
}

int main()
{
    int val = 0;
    AddFour(val);
    AddSix(&val);

    std::cout << "val = " << val << std::endl;
 
    return 0;
}

As can be seen, pointer and reference are both implemented by using a memory address. In the case of AddFour the caller does not even realize that val might be modified while with AddSix, the reference to val has to be explicitly written by using &.

If passing by value needs to be avoided, both pointers and references are a way to achieve this. The following selection of properties contrasts the two methods so it will be easier to decide which to use from the perspective of the use-case at hand:

Pointers can be declared without initialization. This means we can pass an uninitialized pointer to a function who then internally performs the initialization for us.

Pointers can be reassigned to another memory block on the heap.

References are usually easier to use (depending on the expertise level of the programmer). Sometimes however, if a third-party function is used without properly looking at the parameter definition, it might go unnoticed that a value has been modified.

As an experiment, you could use the -m32 compiler flag to build a 32 bit version of the program. This yields the following output:

sizeof(n)

size of int: 4
size of *int: 4
In order to benefit from call-by-reference, the size of the data type passed to the function has to surpass the size of the pointer on the respective architecture (i.e. 32 bit or 64 bit).

3.3. Automatic Allocation (Stack)

When a thread is created, stack memory is allocated by the operating system as a contiguous block. With each new function call or local variable allocation, the stack pointer is moved until eventually it will reach the bottom of said memory block. Once it exceeds this limit (which is called "stack overflow"), the program will crash. To find out the limit of the computer’s stack memory we can make a recursve call on the stack and generate a stack overflow or in terminal: ulimit -s



in the available literature on C++, the terms stack and heap are used regularly, even though this is not formally correct: C++ has the free space, storage classes and the storage duration of objects.

 the stack is the place in virtual memory where the local variables reside, including arguments to functions. Each time a function is called, the stack grows (from top to bottom) and each time a function returns, the stack contracts. When using multiple threads (as in concurrent programming), it is important to know that each thread has its own stack memory - which can be considered thread-safe.

 key properties :

- The stack is a contiguous block of memory. It will not become fragmented (as opposed to the heap) and it has a fixed maximum size.

- When the maximum size of the stack memory is exceeded, a program will crash.

- Allocating and deallocating memory is fast on the stack. It only involves moving the stack pointer to a new position.

3.2. Memory Allocation

Generally, three basic types of memory allocation are supported:

Heap is larger than the stack and only limited by the memory size 
-> here we are more flexible as a c++ dev and its good to use this for big datastructures

stack is managed by the compiler/os but limited in size and allocated mem-space can only be used when its deallocated

a- Static memory allocation is performed for static and global variables, which are stored in the BSS and Data segment. Memory for these types of variables is allocated once when your program is run and persists throughout the life of your program.

b- Automatic memory allocation is performed for function parameters as well as local variables, which are stored on the stack. Memory for these types of variables is allocated when the path of execution enters a scope and freed again once the scope is left.

c- Dynamic memory allocation is a possibility for programs to request memory from the operating system at runtime when needed. This is the major difference between automatic and static allocation, where the size of the variable must be known at compile time. Dynamic memory allocation is not performed on the limited stack but on the heap and is thus (almost) only limited by the size of the address space.

From a programmer’s perspective, stack and heap are the most important areas of program memory.

3.1. Memory model

- each program is assigned its own virtual memory by the operating system. This address space is arranged in a linear fashion with one block of data being stored at each address.
- From a programming perspective though, we are not able to use the entire address space. Instead, the blocks "OS Kernel Space" and "Text" are reserved for the operating system. In kernel space, only the most trusted code is executed - it is fully maintained by the operating system and serves as an interface between the user code and the system kernel.
- The section called 'text' holds the program code generated by the compiler and linker. 

1-Stack
- The stack is a contiguous memory block with a fixed maximum size. If a program exceeds this size, it will crash.
 It is important to know that the stack is managed "automatically" by the compiler, which means we do not have to concern ourselves with allocation and deallocation.

2-Heap
 (also called "free store" in C++) is where data with dynamic storage lives.
It is shared among multiple threads in a program, which means that memory management for the heap needs to take concurrency into account. This makes memory allocations in the heap more complicated than stack allocations. 
in general, managing memory on the heap is more (computationally) expensive for the operating system, which makes it slower than stack memory. Contrary to the stack, the heap is not managed automatically by the system, but by the programmer. If memory is allocated on the heap, it is the programmer’s responsibility to free it again when it is no longer needed. If the programmer manages the heap poorly or not at all, there will be trouble.

3-The BSS (Block Started by Symbol) segment is used in many compilers and linkers for a segment that contains global and static variables that are initialized with zero values. This memory area is suitable, for example, for arrays that are not initialized with predefined values.

4-The Data segment serves the same purpose as the BSS segment with the major difference being that variables in the Data segment have been initialized with a value other than zero. Memory for variables in the Data segment (and in BSS) is allocated once when a program is run and persists throughout its lifetime.

2.5. Virtual memory

- it allows to run programs on different computers
- if ram is limited (atm maybe not so often because ram is gettin cheaper and cheaper) but some cases still need more mem (video editing)
- basic idea is to separate the adresses a program us from addresses in physical mem (mapping function)
- if the available physical memory is less than the upper bound provided by a e.g. 32-bit address space. we need a mapping to another space (like the disc)
With virtual memory, the RAM acts as a cache for the virtual memory space which resides on secondary storage devices. On Windows systems, the file pagefile.sys is such a virtual memory container of varying size. 

2 important terms:

a) memory page
- a number of directly successive memory locations in vmem defined by comp architecture and the os
- computer memory is divided into memory pages of equal size
- the use of mem pages enables the os to use vmem
b) memory frame
- idnetical to mem pages but its location is the physical main memory

2.4. caches

- http://norvig.com/21-days.html#answers (Approximate timing for various operations on a typical PC:)

, programmers can exploit two principles to increase runtime performance:

Temporal locality means that address ranges that are accessed are likely to be used again in the near future. In the course of time, the same memory address is accessed relatively frequently (e.g. in a loop). This property can be used at all levels of the memory hierarchy to keep memory areas accessible as quickly as possible.

Spatial locality means that after an access to an address range, the next access to an address in the immediate vicinity is highly probable (e.g. in arrays). In the course of time, memory addresses that are very close to each other are accessed again multiple times. This can be exploited by moving the adjacent address areas upwards into the next hierarchy level during a memory access.



- cashes are much faster, but signif. smaller than standard RAM
- it holds data which will/might be used very often by the cpu

L1 - fastest and smallest (16-64kb), instructions and data separated (L1i / L1d) In the L1 cache, the most frequently required instructions and data are buffered so that as few accesses as possible to the slow main memory are required. 
This cache avoids delays in data transmission and helps to make optimum use of the CPU's capacity

L2 - close to the cpu and managed by the L2 controller on main board
The size of the L2 cache is usually at or below 2 megabytes.multicore cpus often inside the cpu itself

With a higher clock speed, individual programs run faster, especially those with high computing requirements. As soon as several programs run simultaneously, a larger cache is advantageous. Usually normal desktop computers with a processor that has a large cache are better served than with a processor that has a high clock rate.

L3 - is shared amon all cores of a multicore processor
with L3 cahce coherence protocoll can work much faster. The L3 cache therefore has less the function of a cache, but is intended to simplify and accelerate the cache coherence protocol and the data exchange between the cores.

Debian: lscpu | grep cache

2.3. Types of memory

- The process of activating a more complex system on a simple system is called "bootstrapping": It is a solution for the chicken-egg-problem of starting a software-driven system by itself using software. During bootstrapping, the computer loads the operating system (OS) from the hard drive into random access memory (RAM). RAM is considered "random access" because any memory cell can be accessed directly by intersecting the respective row and column in the matrix-like memory layout. For performance reasons, many parts of the OS are kept in RAM as long as the computer is powered on.

- The bit size of the CPU decides how many bytes of data it can access in RAM memory at the same time. A 16-bit CPU can access 2 bytes (with each byte consisting of 8 bit) while a 64-bit CPU can access 8 bytes at a time.
- The processing speed of the CPU is measured in Gigahertz or Megahertz and denotes the number of operations it can perform in one second.
- From processing speed and bit size, the data rate required to keep the CPU busy can easily be computed by multiplying bit size with processing speed. 

With modern CPUs and ever-increasing speeds, the available RAM in the market will not be fast enough to match the CPU data rate requirements.

2.2. Debugging
- if one need to debug one needs to compile with debuig symbols
--> g++ -g main.cpp

- if one sees only bits and bytes, 0s and 1s it can take away complexity because thats whats in memory

Ressources:

GDB cheatsheet: https://darkdust.net/files/GDB%20Cheat%20Sheet.pdf

2.1. Memory Adresses and HexNumbers
- the low distinctiveness of individual symbols in the presence of noise was a big problem when using the hexadecimal system to transmit data
--> John Atanasoff proposed a coding system that expresses numbers as a sequence of two digits -> binary system was born
- it was much easier to differenciate btw. only two states, esp. at high frquencies and more robust than with 10 digits --> like morse code
- inside each computer every type of information is represented in binary form
- over the years many coding schemes were invented to manipulate the 0s and 1s --> e.g. ASCII
- almost all computers are byte adressed -> using a system that can easily convert into bytes is important -> HEX system (two digits can reference 256 different values)
--> conversion btw. base 2 and base10 is harder than btw. 2 and 16

1.2. Overview
- for every new there need to be a delete, but if you use delete twice you could be in trouble
--> this all leads to smart pointers
